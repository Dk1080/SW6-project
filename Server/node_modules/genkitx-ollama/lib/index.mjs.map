{"version":3,"sources":["../src/index.ts"],"sourcesContent":["/**\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Genkit } from 'genkit';\nimport { logger } from 'genkit/logging';\nimport {\n  GenerateRequest,\n  GenerateResponseData,\n  GenerationCommonConfigSchema,\n  getBasicUsageStats,\n  MessageData,\n} from 'genkit/model';\nimport { GenkitPlugin, genkitPlugin } from 'genkit/plugin';\nimport { defineOllamaEmbedder } from './embeddings.js';\nimport {\n  ApiType,\n  ModelDefinition,\n  RequestHeaders,\n  type OllamaPluginParams,\n} from './types.js';\n\nexport { type OllamaPluginParams };\n\nexport function ollama(params: OllamaPluginParams): GenkitPlugin {\n  return genkitPlugin('ollama', async (ai: Genkit) => {\n    const serverAddress = params.serverAddress;\n    params.models?.map((model) =>\n      ollamaModel(ai, model, serverAddress, params.requestHeaders)\n    );\n    params.embedders?.map((model) =>\n      defineOllamaEmbedder(ai, {\n        name: model.name,\n        modelName: model.name,\n        dimensions: model.dimensions,\n        options: params,\n      })\n    );\n  });\n}\n\nfunction ollamaModel(\n  ai: Genkit,\n  model: ModelDefinition,\n  serverAddress: string,\n  requestHeaders?: RequestHeaders\n) {\n  return ai.defineModel(\n    {\n      name: `ollama/${model.name}`,\n      label: `Ollama - ${model.name}`,\n      configSchema: GenerationCommonConfigSchema,\n      supports: {\n        multiturn: !model.type || model.type === 'chat',\n        systemRole: true,\n      },\n    },\n    async (input, streamingCallback) => {\n      const options: Record<string, any> = {};\n      if (input.config?.temperature !== undefined) {\n        options.temperature = input.config.temperature;\n      }\n      if (input.config?.topP !== undefined) {\n        options.top_p = input.config.topP;\n      }\n      if (input.config?.topK !== undefined) {\n        options.top_k = input.config.topK;\n      }\n      if (input.config?.stopSequences !== undefined) {\n        options.stop = input.config.stopSequences.join('');\n      }\n      if (input.config?.maxOutputTokens !== undefined) {\n        options.num_predict = input.config.maxOutputTokens;\n      }\n      const type = model.type ?? 'chat';\n      const request = toOllamaRequest(\n        model.name,\n        input,\n        options,\n        type,\n        !!streamingCallback\n      );\n      logger.debug(request, `ollama request (${type})`);\n\n      const extraHeaders = requestHeaders\n        ? typeof requestHeaders === 'function'\n          ? await requestHeaders(\n              {\n                serverAddress,\n                model,\n              },\n              input\n            )\n          : requestHeaders\n        : {};\n\n      let res;\n      try {\n        res = await fetch(\n          serverAddress + (type === 'chat' ? '/api/chat' : '/api/generate'),\n          {\n            method: 'POST',\n            body: JSON.stringify(request),\n            headers: {\n              'Content-Type': 'application/json',\n              ...extraHeaders,\n            },\n          }\n        );\n      } catch (e) {\n        const cause = (e as any).cause;\n        if (\n          cause &&\n          cause instanceof Error &&\n          cause.message?.includes('ECONNREFUSED')\n        ) {\n          cause.message += '. Make sure the Ollama server is running.';\n          throw cause;\n        }\n        throw e;\n      }\n      if (!res.body) {\n        throw new Error('Response has no body');\n      }\n\n      let message: MessageData;\n\n      if (streamingCallback) {\n        const reader = res.body.getReader();\n        const textDecoder = new TextDecoder();\n        let textResponse = '';\n        for await (const chunk of readChunks(reader)) {\n          const chunkText = textDecoder.decode(chunk);\n          const json = JSON.parse(chunkText);\n          const message = parseMessage(json, type);\n          streamingCallback({\n            index: 0,\n            content: message.content,\n          });\n          textResponse += message.content[0].text;\n        }\n        message = {\n          role: 'model',\n          content: [\n            {\n              text: textResponse,\n            },\n          ],\n        };\n      } else {\n        const txtBody = await res.text();\n        const json = JSON.parse(txtBody);\n        logger.debug(txtBody, 'ollama raw response');\n\n        message = parseMessage(json, type);\n      }\n\n      return {\n        message,\n        usage: getBasicUsageStats(input.messages, message),\n        finishReason: 'stop',\n      } as GenerateResponseData;\n    }\n  );\n}\n\nfunction parseMessage(response: any, type: ApiType): MessageData {\n  if (response.error) {\n    throw new Error(response.error);\n  }\n  if (type === 'chat') {\n    return {\n      role: toGenkitRole(response.message.role),\n      content: [\n        {\n          text: response.message.content,\n        },\n      ],\n    };\n  } else {\n    return {\n      role: 'model',\n      content: [\n        {\n          text: response.response,\n        },\n      ],\n    };\n  }\n}\n\nfunction toOllamaRequest(\n  name: string,\n  input: GenerateRequest,\n  options: Record<string, any>,\n  type: ApiType,\n  stream: boolean\n) {\n  const request: any = {\n    model: name,\n    options,\n    stream,\n  };\n  if (type === 'chat') {\n    const messages: Message[] = [];\n    input.messages.forEach((m) => {\n      let messageText = '';\n      const images: string[] = [];\n      m.content.forEach((c) => {\n        if (c.text) {\n          messageText += c.text;\n        }\n        if (c.media) {\n          images.push(c.media.url);\n        }\n      });\n      messages.push({\n        role: toOllamaRole(m.role),\n        content: messageText,\n        images: images.length > 0 ? images : undefined,\n      });\n    });\n    request.messages = messages;\n  } else {\n    request.prompt = getPrompt(input);\n    request.system = getSystemMessage(input);\n  }\n  return request;\n}\n\nfunction toOllamaRole(role) {\n  if (role === 'model') {\n    return 'assistant';\n  }\n  return role; // everything else seems to match\n}\n\nfunction toGenkitRole(role) {\n  if (role === 'assistant') {\n    return 'model';\n  }\n  return role; // everything else seems to match\n}\n\nfunction readChunks(reader) {\n  return {\n    async *[Symbol.asyncIterator]() {\n      let readResult = await reader.read();\n      while (!readResult.done) {\n        yield readResult.value;\n        readResult = await reader.read();\n      }\n    },\n  };\n}\n\nfunction getPrompt(input: GenerateRequest): string {\n  return input.messages\n    .filter((m) => m.role !== 'system')\n    .map((m) => m.content.map((c) => c.text).join())\n    .join();\n}\n\nfunction getSystemMessage(input: GenerateRequest): string {\n  return input.messages\n    .filter((m) => m.role === 'system')\n    .map((m) => m.content.map((c) => c.text).join())\n    .join();\n}\n\ninterface Message {\n  role: string;\n  content: string;\n  images?: string[];\n}\n"],"mappings":"AAiBA,SAAS,cAAc;AACvB;AAAA,EAGE;AAAA,EACA;AAAA,OAEK;AACP,SAAuB,oBAAoB;AAC3C,SAAS,4BAA4B;AAU9B,SAAS,OAAO,QAA0C;AAC/D,SAAO,aAAa,UAAU,OAAO,OAAe;AAClD,UAAM,gBAAgB,OAAO;AAC7B,WAAO,QAAQ;AAAA,MAAI,CAAC,UAClB,YAAY,IAAI,OAAO,eAAe,OAAO,cAAc;AAAA,IAC7D;AACA,WAAO,WAAW;AAAA,MAAI,CAAC,UACrB,qBAAqB,IAAI;AAAA,QACvB,MAAM,MAAM;AAAA,QACZ,WAAW,MAAM;AAAA,QACjB,YAAY,MAAM;AAAA,QAClB,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAAA,EACF,CAAC;AACH;AAEA,SAAS,YACP,IACA,OACA,eACA,gBACA;AACA,SAAO,GAAG;AAAA,IACR;AAAA,MACE,MAAM,UAAU,MAAM,IAAI;AAAA,MAC1B,OAAO,YAAY,MAAM,IAAI;AAAA,MAC7B,cAAc;AAAA,MACd,UAAU;AAAA,QACR,WAAW,CAAC,MAAM,QAAQ,MAAM,SAAS;AAAA,QACzC,YAAY;AAAA,MACd;AAAA,IACF;AAAA,IACA,OAAO,OAAO,sBAAsB;AAClC,YAAM,UAA+B,CAAC;AACtC,UAAI,MAAM,QAAQ,gBAAgB,QAAW;AAC3C,gBAAQ,cAAc,MAAM,OAAO;AAAA,MACrC;AACA,UAAI,MAAM,QAAQ,SAAS,QAAW;AACpC,gBAAQ,QAAQ,MAAM,OAAO;AAAA,MAC/B;AACA,UAAI,MAAM,QAAQ,SAAS,QAAW;AACpC,gBAAQ,QAAQ,MAAM,OAAO;AAAA,MAC/B;AACA,UAAI,MAAM,QAAQ,kBAAkB,QAAW;AAC7C,gBAAQ,OAAO,MAAM,OAAO,cAAc,KAAK,EAAE;AAAA,MACnD;AACA,UAAI,MAAM,QAAQ,oBAAoB,QAAW;AAC/C,gBAAQ,cAAc,MAAM,OAAO;AAAA,MACrC;AACA,YAAM,OAAO,MAAM,QAAQ;AAC3B,YAAM,UAAU;AAAA,QACd,MAAM;AAAA,QACN;AAAA,QACA;AAAA,QACA;AAAA,QACA,CAAC,CAAC;AAAA,MACJ;AACA,aAAO,MAAM,SAAS,mBAAmB,IAAI,GAAG;AAEhD,YAAM,eAAe,iBACjB,OAAO,mBAAmB,aACxB,MAAM;AAAA,QACJ;AAAA,UACE;AAAA,UACA;AAAA,QACF;AAAA,QACA;AAAA,MACF,IACA,iBACF,CAAC;AAEL,UAAI;AACJ,UAAI;AACF,cAAM,MAAM;AAAA,UACV,iBAAiB,SAAS,SAAS,cAAc;AAAA,UACjD;AAAA,YACE,QAAQ;AAAA,YACR,MAAM,KAAK,UAAU,OAAO;AAAA,YAC5B,SAAS;AAAA,cACP,gBAAgB;AAAA,cAChB,GAAG;AAAA,YACL;AAAA,UACF;AAAA,QACF;AAAA,MACF,SAAS,GAAG;AACV,cAAM,QAAS,EAAU;AACzB,YACE,SACA,iBAAiB,SACjB,MAAM,SAAS,SAAS,cAAc,GACtC;AACA,gBAAM,WAAW;AACjB,gBAAM;AAAA,QACR;AACA,cAAM;AAAA,MACR;AACA,UAAI,CAAC,IAAI,MAAM;AACb,cAAM,IAAI,MAAM,sBAAsB;AAAA,MACxC;AAEA,UAAI;AAEJ,UAAI,mBAAmB;AACrB,cAAM,SAAS,IAAI,KAAK,UAAU;AAClC,cAAM,cAAc,IAAI,YAAY;AACpC,YAAI,eAAe;AACnB,yBAAiB,SAAS,WAAW,MAAM,GAAG;AAC5C,gBAAM,YAAY,YAAY,OAAO,KAAK;AAC1C,gBAAM,OAAO,KAAK,MAAM,SAAS;AACjC,gBAAMA,WAAU,aAAa,MAAM,IAAI;AACvC,4BAAkB;AAAA,YAChB,OAAO;AAAA,YACP,SAASA,SAAQ;AAAA,UACnB,CAAC;AACD,0BAAgBA,SAAQ,QAAQ,CAAC,EAAE;AAAA,QACrC;AACA,kBAAU;AAAA,UACR,MAAM;AAAA,UACN,SAAS;AAAA,YACP;AAAA,cACE,MAAM;AAAA,YACR;AAAA,UACF;AAAA,QACF;AAAA,MACF,OAAO;AACL,cAAM,UAAU,MAAM,IAAI,KAAK;AAC/B,cAAM,OAAO,KAAK,MAAM,OAAO;AAC/B,eAAO,MAAM,SAAS,qBAAqB;AAE3C,kBAAU,aAAa,MAAM,IAAI;AAAA,MACnC;AAEA,aAAO;AAAA,QACL;AAAA,QACA,OAAO,mBAAmB,MAAM,UAAU,OAAO;AAAA,QACjD,cAAc;AAAA,MAChB;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,aAAa,UAAe,MAA4B;AAC/D,MAAI,SAAS,OAAO;AAClB,UAAM,IAAI,MAAM,SAAS,KAAK;AAAA,EAChC;AACA,MAAI,SAAS,QAAQ;AACnB,WAAO;AAAA,MACL,MAAM,aAAa,SAAS,QAAQ,IAAI;AAAA,MACxC,SAAS;AAAA,QACP;AAAA,UACE,MAAM,SAAS,QAAQ;AAAA,QACzB;AAAA,MACF;AAAA,IACF;AAAA,EACF,OAAO;AACL,WAAO;AAAA,MACL,MAAM;AAAA,MACN,SAAS;AAAA,QACP;AAAA,UACE,MAAM,SAAS;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,gBACP,MACA,OACA,SACA,MACA,QACA;AACA,QAAM,UAAe;AAAA,IACnB,OAAO;AAAA,IACP;AAAA,IACA;AAAA,EACF;AACA,MAAI,SAAS,QAAQ;AACnB,UAAM,WAAsB,CAAC;AAC7B,UAAM,SAAS,QAAQ,CAAC,MAAM;AAC5B,UAAI,cAAc;AAClB,YAAM,SAAmB,CAAC;AAC1B,QAAE,QAAQ,QAAQ,CAAC,MAAM;AACvB,YAAI,EAAE,MAAM;AACV,yBAAe,EAAE;AAAA,QACnB;AACA,YAAI,EAAE,OAAO;AACX,iBAAO,KAAK,EAAE,MAAM,GAAG;AAAA,QACzB;AAAA,MACF,CAAC;AACD,eAAS,KAAK;AAAA,QACZ,MAAM,aAAa,EAAE,IAAI;AAAA,QACzB,SAAS;AAAA,QACT,QAAQ,OAAO,SAAS,IAAI,SAAS;AAAA,MACvC,CAAC;AAAA,IACH,CAAC;AACD,YAAQ,WAAW;AAAA,EACrB,OAAO;AACL,YAAQ,SAAS,UAAU,KAAK;AAChC,YAAQ,SAAS,iBAAiB,KAAK;AAAA,EACzC;AACA,SAAO;AACT;AAEA,SAAS,aAAa,MAAM;AAC1B,MAAI,SAAS,SAAS;AACpB,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEA,SAAS,aAAa,MAAM;AAC1B,MAAI,SAAS,aAAa;AACxB,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEA,SAAS,WAAW,QAAQ;AAC1B,SAAO;AAAA,IACL,QAAQ,OAAO,aAAa,IAAI;AAC9B,UAAI,aAAa,MAAM,OAAO,KAAK;AACnC,aAAO,CAAC,WAAW,MAAM;AACvB,cAAM,WAAW;AACjB,qBAAa,MAAM,OAAO,KAAK;AAAA,MACjC;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,UAAU,OAAgC;AACjD,SAAO,MAAM,SACV,OAAO,CAAC,MAAM,EAAE,SAAS,QAAQ,EACjC,IAAI,CAAC,MAAM,EAAE,QAAQ,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,CAAC,EAC9C,KAAK;AACV;AAEA,SAAS,iBAAiB,OAAgC;AACxD,SAAO,MAAM,SACV,OAAO,CAAC,MAAM,EAAE,SAAS,QAAQ,EACjC,IAAI,CAAC,MAAM,EAAE,QAAQ,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,CAAC,EAC9C,KAAK;AACV;","names":["message"]}